# app.py

import streamlit as st
import cv2
import pandas as pd
import numpy as np
import tensorflow as tf
import os
import time
from pathlib import Path
import tempfile # Th∆∞ vi·ªán ƒë·ªÉ x·ª≠ l√Ω file t·∫°m
import io
import zipfile

# Import c√°c module t·ª´ th∆∞ m·ª•c src
from src import config
from src.vehicle_detector import VehicleDetector
from src.lp_detector import LicensePlateDetector
from src import preprocessor
from src.ocr_reader import OcrReader

# --- C·∫•u h√¨nh trang Streamlit ---
st.set_page_config(
    page_title="H·ªá th·ªëng Nh·∫≠n d·∫°ng Bi·ªÉn s·ªë xe",
    page_icon="üöó",
    layout="wide",
    initial_sidebar_state="expanded",
)

st.title("üöó Giao di·ªán Nh·∫≠n d·∫°ng Bi·ªÉn s·ªë xe (ALPR)")

# --- T·∫£i v√† Cache Model ---
@st.cache_resource
def load_models():
    """T·∫£i t·∫•t c·∫£ c√°c model v√† cache ch√∫ng."""
    with st.spinner('ƒêang t·∫£i c√°c model AI, vui l√≤ng ch·ªù...'):
        vehicle_detector = VehicleDetector(config.VEHICLE_DETECTION_MODEL_PATH)
        lp_detector = LicensePlateDetector(config.LP_DETECTION_MODEL_PATH)
        denoising_model = tf.keras.models.load_model(config.DENOISING_MODEL_PATH, compile=False)
        ocr = OcrReader(config.PADDLEOCR_MODEL_DIR, config.CHAR_DICT_PATH)

    if not all([vehicle_detector.model, lp_detector.model, denoising_model, ocr.ocr_reader]):
        st.error("L·ªói nghi√™m tr·ªçng: M·ªôt ho·∫∑c nhi·ªÅu model kh√¥ng th·ªÉ t·∫£i. Vui l√≤ng ki·ªÉm tra ƒë∆∞·ªùng d·∫´n trong file config.py.")
        return None
    return vehicle_detector, lp_detector, denoising_model, ocr

# T·∫£i model
models = load_models()
if models:
    vehicle_detector, lp_detector, denoising_model, ocr = models
    st.sidebar.success("T·∫£i model th√†nh c√¥ng!")
else:
    st.stop()


def process_single_vehicle(vehicle_crop, vehicle_id, lp_conf, two_line_ratio, verbose=False):
    processed_vehicle_img = vehicle_crop.copy()
    results_list = []

    lp_box = lp_detector.detect(vehicle_crop, lp_conf)
    if lp_box is None:
        return processed_vehicle_img, []

    lp_x1, lp_y1, lp_x2, lp_y2 = lp_box
    lp_crop = vehicle_crop[int(lp_y1):int(lp_y2), int(lp_x1):int(lp_x2)]

    images_for_ocr = preprocessor.process_lp_for_ocr(lp_crop, denoising_model, two_line_ratio=two_line_ratio)
    if not images_for_ocr:
        return processed_vehicle_img, []

    full_text, avg_confidence = ocr.recognize(images_for_ocr, vehicle_id, verbose=verbose)

    if full_text:
        results_list.append({
            'frame': vehicle_id.split('_')[0], 'id_vehicle': vehicle_id,
            'full_text': full_text, 'avg_confidence': f"{avg_confidence:.4f}"
        })

        label = f"LP:{full_text}"
        cv2.rectangle(processed_vehicle_img, (int(lp_x1), int(lp_y1)), (int(lp_x2), int(lp_y2)), (36, 255, 12), 2)
        (w, h), _ = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.7, 2)
        cv2.rectangle(processed_vehicle_img, (int(lp_x1), int(lp_y1) - h - 10), (int(lp_x1) + w, int(lp_y1)), (36, 255, 12), -1)
        cv2.putText(processed_vehicle_img, label, (int(lp_x1), int(lp_y1) - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 0), 2)

    return processed_vehicle_img, results_list


def run_alpr_on_frame(frame, image_name, vehicle_conf, lp_conf, two_line_ratio, verbose=False):
    output_image = frame.copy()
    all_results = []

    status_context = st.status(f"üîç ƒêang x·ª≠ l√Ω {image_name}...", expanded=True) if verbose else None

    vehicle_boxes = vehicle_detector.detect(frame, vehicle_conf)

    if not np.any(vehicle_boxes):
        if verbose and status_context:
            status_context.update(label="Kh√¥ng t√¨m th·∫•y xe.", state="warning", expanded=False)
        return output_image, []

    if verbose and status_context:
        status_context.update(label=f"T√¨m th·∫•y {len(vehicle_boxes)} xe. ƒêang nh·∫≠n d·∫°ng...", state="running")

    for i, (x1, y1, x2, y2) in enumerate(vehicle_boxes):
        vehicle_id = f"{Path(image_name).stem}_{i}"
        vehicle_crop = frame[int(y1):int(y2), int(x1):int(x2)]

        processed_vehicle, results = process_single_vehicle(
            vehicle_crop, vehicle_id, lp_conf, two_line_ratio, verbose=verbose
        )

        output_image[int(y1):int(y2), int(x1):int(x2)] = processed_vehicle

        if results:
            all_results.extend(results)
            cv2.rectangle(output_image, (int(x1), int(y1)), (int(x2), int(y2)), (36, 255, 12), 2)

    if verbose and status_context:
        status_context.update(label="Ho√†n t·∫•t!", state="complete", expanded=False)

    return output_image, all_results

# --- GIAO DI·ªÜN CH√çNH ---

st.sidebar.header("Ch·ªçn ch·∫ø ƒë·ªô")
app_mode = st.sidebar.selectbox("Vui l√≤ng ch·ªçn ch·∫ø ƒë·ªô x·ª≠ l√Ω:",
                                ["Ch·ªçn ch·∫ø ƒë·ªô...", "ALPR 1 ·∫£nh", "ALPR 1 th∆∞ m·ª•c",  "ALPR t·ª´ Video"])

st.sidebar.header("‚öôÔ∏è Tinh ch·ªânh tham s·ªë")
st.sidebar.info("C√°c tham s·ªë n√†y s·∫Ω ƒë∆∞·ª£c √°p d·ª•ng cho t·∫•t c·∫£ c√°c ch·∫ø ƒë·ªô.")
vehicle_conf_adj = st.sidebar.slider("Ng∆∞·ª°ng tin c·∫≠y ph√°t hi·ªán XE", 0.05, 0.95, config.VEHICLE_CONF_THRESHOLD, 0.05)
lp_conf_adj = st.sidebar.slider("Ng∆∞·ª°ng tin c·∫≠y ph√°t hi·ªán BI·ªÇN S·ªê", 0.05, 0.95, config.LP_CONF_THRESHOLD, 0.05)
ratio_adj = st.sidebar.slider("T·ª∑ l·ªá nh·∫≠n di·ªán bi·ªÉn 2 d√≤ng", 0.2, 1.0, config.TWO_LINE_LP_ASPECT_RATIO_THRESHOLD, 0.05,
                            help="Gi√° tr·ªã c√†ng th·∫•p, c√†ng d·ªÖ nh·∫≠n di·ªán bi·ªÉn s·ªë d·ªçc (2 d√≤ng).")

# --- CH·∫æ ƒê·ªò 1: X·ª¨ L√ù 1 ·∫¢NH ---
if app_mode == "ALPR 1 ·∫£nh":
    st.header("Ch·∫ø ƒë·ªô 1: X·ª≠ l√Ω m·ªôt ·∫£nh duy nh·∫•t")
    uploaded_file = st.file_uploader("T·∫£i l√™n m·ªôt ·∫£nh (JPG, PNG)...", type=["jpg", "jpeg", "png"])

    if uploaded_file is not None:
        file_bytes = np.asarray(bytearray(uploaded_file.read()), dtype=np.uint8)
        frame = cv2.imdecode(file_bytes, 1)

        col1, col2 = st.columns(2)
        with col1:
            st.image(frame, channels="BGR", caption="·∫¢nh g·ªëc")

        if st.button("üöÄ B·∫Øt ƒë·∫ßu x·ª≠ l√Ω"):
            result_image, results_list = run_alpr_on_frame(
                frame, uploaded_file.name, vehicle_conf_adj, lp_conf_adj, ratio_adj, verbose=True
            )

            with col2:
                st.image(result_image, channels="BGR", caption="·∫¢nh k·∫øt qu·∫£")

            if results_list:
                st.subheader("K·∫øt qu·∫£ nh·∫≠n di·ªán:")
                df_results = pd.DataFrame(results_list)
                st.dataframe(df_results)

                @st.cache_data
                def convert_df_to_csv(df):
                    return df.to_csv(index=False).encode('utf-8')

                csv_data = convert_df_to_csv(df_results)
                st.download_button(
                    label="üì• T·∫£i k·∫øt qu·∫£ (CSV)",
                    data=csv_data,
                    file_name=f"result_{Path(uploaded_file.name).stem}.csv",
                    mime='text/csv',
                )
            else:
                st.info("Kh√¥ng nh·∫≠n di·ªán ƒë∆∞·ª£c bi·ªÉn s·ªë n√†o trong ·∫£nh.")

# --- CH·∫æ ƒê·ªò 2: X·ª¨ L√ù TH∆Ø M·ª§C (ƒê√É C·∫¨P NH·∫¨T) ---
elif app_mode == "ALPR 1 th∆∞ m·ª•c":
    st.header("Ch·∫ø ƒë·ªô 2: X·ª≠ l√Ω nhi·ªÅu ·∫£nh t·ª´ m·ªôt th∆∞ m·ª•c")
    
    # Cho ph√©p ng∆∞·ªùi d√πng t·∫£i l√™n nhi·ªÅu file
    uploaded_files = st.file_uploader(
        "T·∫£i l√™n c√°c ·∫£nh (JPG, PNG) t·ª´ th∆∞ m·ª•c c·ªßa b·∫°n...", 
        type=["jpg", "jpeg", "png"],
        accept_multiple_files=True
    )

    if uploaded_files:
        st.info(f"ƒê√£ ch·ªçn **{len(uploaded_files)}** ·∫£nh. Nh·∫•n n√∫t b√™n d∆∞·ªõi ƒë·ªÉ b·∫Øt ƒë·∫ßu.")
        
        if st.button("üìÅ B·∫Øt ƒë·∫ßu x·ª≠ l√Ω c√°c ·∫£nh ƒë√£ ch·ªçn"):
            progress_bar = st.progress(0, text="B·∫Øt ƒë·∫ßu x·ª≠ l√Ω...")
            all_results = []
            
            # D√πng io.BytesIO ƒë·ªÉ t·∫°o file zip trong b·ªô nh·ªõ
            zip_buffer = io.BytesIO()
            
            # Dictionary ƒë·ªÉ l∆∞u ·∫£nh k·∫øt qu·∫£ trong b·ªô nh·ªõ
            processed_images_data = {}

            for i, uploaded_file in enumerate(uploaded_files):
                image_name = uploaded_file.name
                progress_text = f"ƒêang x·ª≠ l√Ω ·∫£nh: {image_name} ({i + 1}/{len(uploaded_files)})"
                progress_bar.progress((i + 1) / len(uploaded_files), text=progress_text)
                
                # ƒê·ªçc ·∫£nh t·ª´ file t·∫£i l√™n
                file_bytes = np.asarray(bytearray(uploaded_file.read()), dtype=np.uint8)
                frame = cv2.imdecode(file_bytes, 1)

                # Ch·∫°y ALPR tr√™n ·∫£nh
                result_image, results_list = run_alpr_on_frame(
                    frame, image_name, vehicle_conf_adj, lp_conf_adj, ratio_adj, verbose=False
                )
                
                # M√£ h√≥a ·∫£nh k·∫øt qu·∫£ sang ƒë·ªãnh d·∫°ng PNG ƒë·ªÉ l∆∞u v√†o b·ªô nh·ªõ
                is_success, buffer = cv2.imencode(".png", result_image)
                if is_success:
                    processed_images_data[image_name] = io.BytesIO(buffer)

                # Th√™m t√™n file v√†o k·∫øt qu·∫£ ƒë·ªÉ xu·∫•t CSV
                if results_list:
                    for result in results_list:
                        result['image_name'] = image_name
                    all_results.extend(results_list)
                
                time.sleep(0.1) # D·ª´ng m·ªôt ch√∫t ƒë·ªÉ UI m∆∞·ª£t h∆°n

            progress_bar.empty()
            st.success("üéâ Ho√†n t·∫•t x·ª≠ l√Ω t·∫•t c·∫£ ·∫£nh!")

            # --- T·∫†O C√ÅC N√öT DOWNLOAD ---
            col1, col2 = st.columns(2)

            # 1. N√öT T·∫¢I FILE ZIP
            with col1:
                if processed_images_data:
                    with zipfile.ZipFile(zip_buffer, "w", zipfile.ZIP_DEFLATED) as zf:
                        for filename, data in processed_images_data.items():
                            zf.writestr(f"processed_{filename}", data.getvalue())
                    
                    st.download_button(
                        label="üì• T·∫£i t·∫•t c·∫£ ·∫£nh k·∫øt qu·∫£ (.zip)",
                        data=zip_buffer.getvalue(),
                        file_name="processed_images.zip",
                        mime="application/zip",
                        use_container_width=True
                    )

            # 2. N√öT T·∫¢I FILE CSV
            with col2:
                if all_results:
                    df = pd.DataFrame(all_results)
                    # ƒê·ªïi t√™n v√† s·∫Øp x·∫øp l·∫°i c√°c c·ªôt theo y√™u c·∫ßu
                    df.rename(columns={
                        'id_vehicle': 'vehicle_id',
                        'full_text': 'text',
                        'avg_confidence': 'confidence'
                    }, inplace=True)
                    df_final = df[['image_name', 'vehicle_id', 'text', 'confidence']]

                    csv_data = df_final.to_csv(index=False).encode('utf-8')
                    st.download_button(
                        label="üì• T·∫£i t·∫•t c·∫£ k·∫øt qu·∫£ (.csv)",
                        data=csv_data,
                        file_name="folder_alpr_results.csv",
                        mime="text/csv",
                        use_container_width=True
                    )
            
            # Hi·ªÉn th·ªã b·∫£ng k·∫øt qu·∫£ t·ªïng h·ª£p
            if all_results:
                st.subheader("T·ªïng h·ª£p k·∫øt qu·∫£:")
                st.dataframe(df_final)
            else:
                st.info("Kh√¥ng nh·∫≠n di·ªán ƒë∆∞·ª£c bi·ªÉn s·ªë n√†o trong c√°c ·∫£nh ƒë√£ ch·ªçn.")


# --- CH·∫æ ƒê·ªò 3: X·ª¨ L√ù VIDEO ---
# --- CH·∫æ ƒê·ªò 3: X·ª¨ L√ù VIDEO (ƒê√É C·∫¨P NH·∫¨T V·ªöI B·ªò THEO D√ïI XE) ---
elif app_mode == "ALPR t·ª´ Video":
    st.header("Ch·∫ø ƒë·ªô 3: X·ª≠ l√Ω t·ª´ m·ªôt file Video")
    st.sidebar.subheader("Tinh ch·ªânh Video")
    frame_skip = st.sidebar.slider("X·ª≠ l√Ω m·ªói N khung h√¨nh (frame skip)", 1, 30, 10)
    uploaded_video = st.file_uploader("T·∫£i l√™n m·ªôt video (MP4, MOV, AVI)...", type=["mp4", "mov", "avi"])

    roi_rect = None
    if uploaded_video is not None:
        tfile = tempfile.NamedTemporaryFile(delete=False)
        tfile.write(uploaded_video.read())
        tfile.close() 
        
        video_filename = uploaded_video.name
        cap_preview = cv2.VideoCapture(tfile.name)
        ret, first_frame = cap_preview.read()
        cap_preview.release()

        if ret:
            st.subheader("B∆∞·ªõc 1: (B·∫Øt bu·ªôc) X√°c ƒë·ªãnh V√πng Quan T√¢m (Region of Interest)")
            st.info("B·ªô ƒë·∫øm s·∫Ω ch·ªâ ho·∫°t ƒë·ªông v·ªõi nh·ªØng xe ƒëi v√†o v√πng ROI b·∫°n ƒë√£ v·∫Ω.")
            
            preview_frame = first_frame.copy()
            height, width, _ = preview_frame.shape

            col1, col2 = st.columns(2)
            with col1:
                x_min = st.slider("ROI X-min", 0, width, 0, 1)
                x_max = st.slider("ROI X-max", 0, width, width, 1)
            with col2:
                y_min = st.slider("ROI Y-min", 0, height, 0, 1)
                y_max = st.slider("ROI Y-max", 0, height, height, 1)

            if x_min >= x_max: x_max = x_min + 1
            if y_min >= y_max: y_max = y_min + 1

            roi_rect = (x_min, y_min, x_max, y_max)
            cv2.rectangle(preview_frame, (x_min, y_min), (x_max, y_max), (36, 255, 12), 3)
            st.image(preview_frame, channels="BGR", caption="Khung h√¨nh ƒë·∫ßu ti√™n v·ªõi ROI")

        st.subheader("B∆∞·ªõc 2: B·∫Øt ƒë·∫ßu x·ª≠ l√Ω video")
        if st.button("üé¨ B·∫Øt ƒë·∫ßu x·ª≠ l√Ω Video"):
            if roi_rect is None or (roi_rect[0] == 0 and roi_rect[2] == width and roi_rect[1] == 0 and roi_rect[3] == height):
                st.warning("Vui l√≤ng x√°c ƒë·ªãnh m·ªôt v√πng ROI c·ª• th·ªÉ ·ªü B∆∞·ªõc 1 ƒë·ªÉ b·ªô ƒë·∫øm ho·∫°t ƒë·ªông ch√≠nh x√°c.")
                st.stop()

            cap = cv2.VideoCapture(tfile.name)
            total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
            fps = cap.get(cv2.CAP_PROP_FPS)
            out_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
            out_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
            output_video_path = tempfile.NamedTemporaryFile(delete=False, suffix='.mp4').name
            fourcc = cv2.VideoWriter_fourcc(*'mp4v')
            out_writer = cv2.VideoWriter(output_video_path, fourcc, fps, (out_width, out_height))

            # --- KH·ªûI T·∫†O B·ªò THEO D√ïI (TRACKER) ---
            vehicle_tracker = {}  # {tracker_id: {'center': (x,y), 'unseen_frames': 0, 'id_vehicle': None}}
            next_tracker_id = 0
            vehicle_pass_count = 0
            DISTANCE_THRESHOLD = 75  # Ng∆∞·ª°ng kho·∫£ng c√°ch ƒë·ªÉ coi l√† c√πng m·ªôt xe (pixel)
            MAX_UNSEEN_FRAMES = 10 # S·ªë frame cho ph√©p "m·∫•t d·∫•u" m·ªôt xe tr∆∞·ªõc khi x√≥a

            progress_bar = st.progress(0, text="B·∫Øt ƒë·∫ßu x·ª≠ l√Ω...")
            status_text = st.empty()
            image_placeholder = st.empty()
            all_video_results = []
            frame_count = 0

            with st.spinner("ƒêang x·ª≠ l√Ω video v·ªõi b·ªô theo d√µi..."):
                while cap.isOpened():
                    ret, frame = cap.read()
                    if not ret: break
                    frame_count += 1
                    
                    display_frame = frame.copy()
                    rx1, ry1, rx2, ry2 = roi_rect
                    cv2.rectangle(display_frame, (rx1, ry1), (rx2, ry2), (36, 255, 12), 2)

                    # Ch·ªâ x·ª≠ l√Ω t·∫°i c√°c frame ƒë∆∞·ª£c ch·ªâ ƒë·ªãnh (frame_skip)
                    if frame_count % frame_skip == 0:
                        status_text.text(f"ƒêang x·ª≠ l√Ω khung h√¨nh {frame_count}/{total_frames}...")
                        
                        # --- LOGIC THEO D√ïI & ƒê·∫æM XE ---
                        vehicle_boxes = vehicle_detector.detect(frame, vehicle_conf_adj)
                        
                        current_detections = []
                        for (x1, y1, x2, y2) in vehicle_boxes:
                            center = (int((x1 + x2) / 2), int((y1 + y2) / 2))
                            current_detections.append({'center': center, 'box': (x1, y1, x2, y2), 'matched': False})
                        
                        matched_tracker_ids_this_frame = set()

                        # 1. C·ªë g·∫Øng kh·ªõp c√°c xe m·ªõi ph√°t hi·ªán v·ªõi c√°c xe ƒë√£ theo d√µi
                        for tracker_id, tracker_data in vehicle_tracker.items():
                            min_dist = float('inf')
                            best_match_idx = -1
                            for i, detection in enumerate(current_detections):
                                if not detection['matched']:
                                    dist = np.linalg.norm(np.array(tracker_data['center']) - np.array(detection['center']))
                                    if dist < DISTANCE_THRESHOLD and dist < min_dist:
                                        min_dist = dist
                                        best_match_idx = i
                            
                            if best_match_idx != -1:
                                current_detections[best_match_idx]['matched'] = True
                                vehicle_tracker[tracker_id]['center'] = current_detections[best_match_idx]['center']
                                vehicle_tracker[tracker_id]['unseen_frames'] = 0
                                matched_tracker_ids_this_frame.add(tracker_id)
                                # G√°n tracker_id ƒë√£ c√≥ cho xe ƒë∆∞·ª£c kh·ªõp
                                current_detections[best_match_idx]['tracker_id'] = tracker_id

                        # 2. T·∫°o tracker m·ªõi cho c√°c xe kh√¥ng kh·ªõp
                        for detection in current_detections:
                            if not detection['matched']:
                                vehicle_tracker[next_tracker_id] = {'center': detection['center'], 'unseen_frames': 0, 'id_vehicle': None}
                                matched_tracker_ids_this_frame.add(next_tracker_id)
                                detection['tracker_id'] = next_tracker_id
                                next_tracker_id += 1

                        # 3. X·ª≠ l√Ω xe, ki·ªÉm tra ROI v√† g√°n ID n·∫øu c·∫ßn
                        for detection in current_detections:
                            center = detection['center']
                            tracker_id = detection.get('tracker_id')
                            if tracker_id is None: continue

                            # Ki·ªÉm tra xe c√≥ n·∫±m trong ROI kh√¥ng
                            if rx1 < center[0] < rx2 and ry1 < center[1] < ry2:
                                # N·∫øu xe n·∫±m trong ROI v√† ch∆∞a ƒë∆∞·ª£c ƒë·∫øm -> ƒê·∫øm v√† x·ª≠ l√Ω
                                if vehicle_tracker[tracker_id]['id_vehicle'] is None:
                                    vehicle_pass_count += 1
                                    assigned_id = vehicle_pass_count
                                    vehicle_tracker[tracker_id]['id_vehicle'] = assigned_id
                                    
                                    # X·ª≠ l√Ω nh·∫≠n d·∫°ng bi·ªÉn s·ªë cho xe v·ª´a ƒë∆∞·ª£c ƒë·∫øm
                                    x1, y1, x2, y2 = detection['box']
                                    vehicle_crop = frame[int(y1):int(y2), int(x1):int(x2)]
                                    processed_vehicle, results = process_single_vehicle(
                                        vehicle_crop, f"v_{assigned_id}", lp_conf_adj, ratio_adj, verbose=False
                                    )
                                    display_frame[int(y1):int(y2), int(x1):int(x2)] = processed_vehicle

                                    if results:
                                        for r in results:
                                            r['frame'] = frame_count
                                            r['id_vehicle'] = assigned_id # Ghi ƒë√® ID cho ƒë√∫ng
                                        all_video_results.extend(results)
                                        cv2.rectangle(display_frame, (int(x1), int(y1)), (int(x2), int(y2)), (36, 255, 12), 2)
                                
                                # Hi·ªÉn th·ªã ID ƒë√£ g√°n l√™n xe
                                assigned_id = vehicle_tracker[tracker_id]['id_vehicle']
                                id_label = f"ID: {assigned_id}"
                                (w, h), _ = cv2.getTextSize(id_label, cv2.FONT_HERSHEY_SIMPLEX, 0.9, 2)
                                cv2.rectangle(display_frame, (int(detection['box'][0]), int(detection['box'][1]) - h - 10), (int(detection['box'][0]) + w, int(detection['box'][1])), (0,0,255), -1)
                                cv2.putText(display_frame, id_label, (int(detection['box'][0]), int(detection['box'][1]) - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (255,255,255), 2)
                        
                        # 4. X√≥a c√°c tracker ƒë√£ m·∫•t d·∫•u qu√° l√¢u
                        lost_trackers = [tid for tid, tdata in vehicle_tracker.items() if tid not in matched_tracker_ids_this_frame]
                        for tid in lost_trackers:
                            vehicle_tracker[tid]['unseen_frames'] += 1
                            if vehicle_tracker[tid]['unseen_frames'] > MAX_UNSEEN_FRAMES:
                                del vehicle_tracker[tid]

                    # Ghi frame v√†o video output
                    out_writer.write(display_frame)
                    image_placeholder.image(display_frame, channels="BGR")
                    progress_bar.progress(frame_count / total_frames)

            cap.release()
            out_writer.release()
            os.remove(tfile.name) 
            st.success("üéâ Ho√†n t·∫•t x·ª≠ l√Ω video!")

            # --- HI·ªÇN TH·ªä V√Ä T·∫¢I K·∫æT QU·∫¢ VIDEO ---
            st.subheader("K·∫øt qu·∫£ Video ƒë√£ x·ª≠ l√Ω")
            with open(output_video_path, 'rb') as f:
                video_bytes = f.read()
            st.video(video_bytes)
            st.download_button(label="üì• T·∫£i video ƒë√£ x·ª≠ l√Ω", data=video_bytes, file_name=f"processed_{video_filename}", mime="video/mp4")
            os.remove(output_video_path)

            if all_video_results:
                st.subheader("T·ªïng h·ª£p c√°c l∆∞·ª£t nh·∫≠n di·ªán trong video:")
                df_all = pd.DataFrame(all_video_results)
                # ƒê·ªïi t√™n c·ªôt v√† s·∫Øp x·∫øp l·∫°i
                df_all.rename(columns={'full_text': 'text', 'avg_confidence': 'confidence'}, inplace=True)
                # Gi·ªØ l·∫°i k·∫øt qu·∫£ t·ªët nh·∫•t cho m·ªói ID xe (l∆∞·ª£t c√≥ confidence cao nh·∫•t)
                df_final = df_all.loc[df_all.groupby('id_vehicle')['confidence'].idxmax()]
                df_final = df_final[['frame', 'id_vehicle', 'text', 'confidence']].sort_values(by='id_vehicle')
                
                st.dataframe(df_final)

                csv_data = df_final.to_csv(index=False).encode('utf-8')
                st.download_button(label="üì• T·∫£i k·∫øt qu·∫£ nh·∫≠n di·ªán (CSV)", data=csv_data, file_name=f"results_{Path(video_filename).stem}.csv", mime='text/csv')
            else:
                st.info("Kh√¥ng nh·∫≠n di·ªán ƒë∆∞·ª£c bi·ªÉn s·ªë n√†o h·ª£p l·ªá trong video.")

# --- M√†n h√¨nh ch·ªù ---
else:
    st.info("Vui l√≤ng ch·ªçn m·ªôt ch·∫ø ƒë·ªô x·ª≠ l√Ω t·ª´ thanh c√¥ng c·ª• b√™n tr√°i.")
    st.image("https://www.luxoft.com/upload/medialibrary/729/automated_license_plate_recognition.png")