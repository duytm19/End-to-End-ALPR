# app.py

import streamlit as st
import cv2
import pandas as pd
import numpy as np
import tensorflow as tf
import os
import time
from pathlib import Path
import tempfile # Th√™m th∆∞ vi·ªán ƒë·ªÉ x·ª≠ l√Ω file t·∫°m

# Import c√°c module t·ª´ th∆∞ m·ª•c src
from src import config
from src.vehicle_detector import VehicleDetector
from src.lp_detector import LicensePlateDetector
from src import preprocessor
from src.ocr_reader import OcrReader

# --- C·∫•u h√¨nh trang Streamlit ---
st.set_page_config(
    page_title="H·ªá th·ªëng Nh·∫≠n d·∫°ng Bi·ªÉn s·ªë xe",
    page_icon="üöó",
    layout="wide",
    initial_sidebar_state="expanded",
)

st.title("üöó Giao di·ªán Nh·∫≠n d·∫°ng Bi·ªÉn s·ªë xe (ALPR)")

# --- T·∫£i v√† Cache Model ---
# S·ª≠ d·ª•ng @st.cache_resource ƒë·ªÉ ƒë·∫£m b·∫£o model ch·ªâ ƒë∆∞·ª£c t·∫£i m·ªôt l·∫ßn
@st.cache_resource
def load_models():
    """T·∫£i t·∫•t c·∫£ c√°c model v√† cache ch√∫ng."""
    with st.spinner('ƒêang t·∫£i c√°c model AI, vui l√≤ng ch·ªù...'):
        vehicle_detector = VehicleDetector(config.VEHICLE_DETECTION_MODEL_PATH)
        lp_detector = LicensePlateDetector(config.LP_DETECTION_MODEL_PATH)
        denoising_model = tf.keras.models.load_model(config.DENOISING_MODEL_PATH, compile=False)
        ocr = OcrReader(config.PADDLEOCR_MODEL_DIR, config.CHAR_DICT_PATH)
    
    # Ki·ªÉm tra xem c√°c model ƒë√£ ƒë∆∞·ª£c t·∫£i th√†nh c√¥ng ch∆∞a
    if not all([vehicle_detector.model, lp_detector.model, denoising_model, ocr.ocr_reader]):
        st.error("L·ªói nghi√™m tr·ªçng: M·ªôt ho·∫∑c nhi·ªÅu model kh√¥ng th·ªÉ t·∫£i. Vui l√≤ng ki·ªÉm tra ƒë∆∞·ªùng d·∫´n trong file config.py.")
        return None
    return vehicle_detector, lp_detector, denoising_model, ocr

# T·∫£i model
models = load_models()
if models:
    vehicle_detector, lp_detector, denoising_model, ocr = models
    st.sidebar.success("T·∫£i model th√†nh c√¥ng!")
else:
    st.stop()


# THAY TH·∫æ TO√ÄN B·ªò H√ÄM C≈® B·∫∞NG H√ÄM M·ªöI N√ÄY
def process_image(frame, image_name, verbose=False):
    """
    H√†m x·ª≠ l√Ω ·∫£nh/khung h√¨nh.
    - verbose=True: In ra ƒë·∫ßy ƒë·ªß log, d√πng cho ·∫£nh ƒë∆°n.
    - verbose=False: Ch·∫°y trong im l·∫∑ng, d√πng cho video.
    """
    output_image = frame.copy()
    csv_results = []

    if verbose:
        os.makedirs(config.OUTPUT_DIR, exist_ok=True)
        os.makedirs(config.PROCESSED_LP_DIR, exist_ok=True)
        os.makedirs(config.SUCCESSFUL_VEHICLES_DIR, exist_ok=True)

    # D√πng st.status ch·ªâ ·ªü ch·∫ø ƒë·ªô verbose
    status_context = st.status(f"üîç ƒêang ph√°t hi·ªán xe trong ·∫£nh {image_name}...", expanded=True) if verbose else None

    vehicle_boxes = vehicle_detector.detect(frame, config.VEHICLE_CONF_THRESHOLD)
    
    if not np.any(vehicle_boxes):
        if verbose and status_context:
            st.warning("Kh√¥ng ph√°t hi·ªán ƒë∆∞·ª£c xe n√†o.")
            status_context.update(label="Kh√¥ng t√¨m th·∫•y xe.", state="complete")
        return output_image, []

    if verbose and status_context:
        st.write(f"‚úÖ T√¨m th·∫•y **{len(vehicle_boxes)}** xe.")
        status_context.update(label="Ph√°t hi·ªán xe ho√†n t·∫•t!", state="running")

    for i, (x1, y1, x2, y2) in enumerate(vehicle_boxes):
        vehicle_id = f"{Path(image_name).stem}_{i}"
        if verbose:
            st.write(f"--- ƒêang x·ª≠ l√Ω **Xe ID: {vehicle_id}** ---")
        
        vehicle_crop = frame[int(y1):int(y2), int(x1):int(x2)]
        lp_box = lp_detector.detect(vehicle_crop, config.LP_CONF_THRESHOLD)
        if lp_box is None:
            if verbose: st.write(f"  - ‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y bi·ªÉn s·ªë tr√™n Xe ID: {vehicle_id}.")
            continue
        
        if verbose: st.write(f"  - ‚úÖ T√¨m th·∫•y bi·ªÉn s·ªë. B·∫Øt ƒë·∫ßu ti·ªÅn x·ª≠ l√Ω...")
        lp_x1, lp_y1, lp_x2, lp_y2 = lp_box
        lp_crop = vehicle_crop[int(lp_y1):int(lp_y2), int(lp_x1):int(lp_x2)]

        images_for_ocr = preprocessor.process_lp_for_ocr(lp_crop, denoising_model)
        if not images_for_ocr:
            if verbose: st.write("  - ‚ö†Ô∏è Ti·ªÅn x·ª≠ l√Ω kh√¥ng t·∫°o ra ·∫£nh ƒë·ªÉ nh·∫≠n di·ªán.")
            continue
        
        full_text, avg_confidence = ocr.recognize(images_for_ocr, vehicle_id)

        if full_text:
            if verbose: st.write(f"  - ‚úÖ **K·∫øt qu·∫£:** `{full_text}` (ƒê·ªô tin c·∫≠y: {avg_confidence:.2f})")
            
            csv_results.append({
                'frame': image_name, 'id_vehicle': vehicle_id,
                'full_text': full_text, 'avg_confidence': f"{avg_confidence:.4f}"
            })
            
            label = f"ID:{i} LP:{full_text}"
            cv2.rectangle(output_image, (int(x1), int(y1)), (int(x2), int(y2)), (36, 255, 12), 2)
            (w, h), _ = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.7, 2)
            cv2.rectangle(output_image, (int(x1), int(y1) - h - 10), (int(x1) + w, int(y1)), (36, 255, 12), -1)
            cv2.putText(output_image, label, (int(x1), int(y1) - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 0), 2)

            if verbose:
                try:
                    safe_lp_text = "".join(c for c in full_text if c.isalnum())
                    vehicle_filename = f"{Path(image_name).stem}_id{i}_{safe_lp_text}.jpg"
                    save_path = os.path.join(config.SUCCESSFUL_VEHICLES_DIR, vehicle_filename)
                    cv2.imwrite(save_path, vehicle_crop)
                    st.write(f"  - üíæ ƒê√£ l∆∞u ·∫£nh xe th√†nh c√¥ng v√†o: `{save_path}`")
                except Exception as e:
                    st.warning(f"  - ‚ö†Ô∏è ƒê√£ c√≥ l·ªói khi l∆∞u ·∫£nh xe: {e}")
        else:
            if verbose: st.write(f"  - ‚ö†Ô∏è OCR th·∫•t b·∫°i cho Xe ID: {vehicle_id}.")
    
    if verbose and status_context:
        status_context.update(label="Ho√†n t·∫•t x·ª≠ l√Ω!", state="complete")
        
    return output_image, csv_results


# --- GIAO DI·ªÜN CH√çNH ---

st.sidebar.header("Ch·ªçn ch·∫ø ƒë·ªô")
app_mode = st.sidebar.selectbox("Vui l√≤ng ch·ªçn ch·∫ø ƒë·ªô x·ª≠ l√Ω:",
                                ["Ch·ªçn ch·∫ø ƒë·ªô...", "ALPR 1 ·∫£nh", "ALPR 1 th∆∞ m·ª•c",  "ALPR t·ª´ Video"])

# --- CH·∫æ ƒê·ªò 1: X·ª¨ L√ù 1 ·∫¢NH ---
if app_mode == "ALPR 1 ·∫£nh":
    st.header("Ch·∫ø ƒë·ªô 1: X·ª≠ l√Ω m·ªôt ·∫£nh duy nh·∫•t")
    uploaded_file = st.file_uploader("T·∫£i l√™n m·ªôt ·∫£nh (JPG, PNG)...", type=["jpg", "jpeg", "png"])

    if uploaded_file is not None:
        # ƒê·ªçc ·∫£nh t·ª´ file t·∫£i l√™n
        file_bytes = np.asarray(bytearray(uploaded_file.read()), dtype=np.uint8)
        frame = cv2.imdecode(file_bytes, 1)

        col1, col2 = st.columns(2)
        with col1:
            st.image(frame, channels="BGR", caption="·∫¢nh g·ªëc")

        if st.button("üöÄ B·∫Øt ƒë·∫ßu x·ª≠ l√Ω"):
            result_image, results_list = process_image(frame, uploaded_file.name)
            
            with col2:
                st.image(result_image, channels="BGR", caption="·∫¢nh k·∫øt qu·∫£")
            
            if results_list:
                st.subheader("K·∫øt qu·∫£ nh·∫≠n di·ªán:")
                df_results = pd.DataFrame(results_list)
                st.dataframe(df_results)

                # T·∫°o n√∫t download CSV
                @st.cache_data
                def convert_df_to_csv(df):
                    return df.to_csv(index=False).encode('utf-8')
                
                csv_data = convert_df_to_csv(df_results)
                st.download_button(
                    label="üì• T·∫£i k·∫øt qu·∫£ (CSV)",
                    data=csv_data,
                    file_name=f"result_{Path(uploaded_file.name).stem}.csv",
                    mime='text/csv',
                )
            else:
                st.info("Kh√¥ng nh·∫≠n di·ªán ƒë∆∞·ª£c bi·ªÉn s·ªë n√†o trong ·∫£nh.")


# --- CH·∫æ ƒê·ªò 2: X·ª¨ L√ù TH∆Ø M·ª§C ---
elif app_mode == "ALPR 1 th∆∞ m·ª•c":
    st.header("Ch·∫ø ƒë·ªô 2: X·ª≠ l√Ω to√†n b·ªô ·∫£nh trong m·ªôt th∆∞ m·ª•c")
    folder_path = st.text_input("Nh·∫≠p ƒë∆∞·ªùng d·∫´n ƒë·∫øn th∆∞ m·ª•c ch·ª©a ·∫£nh:")

    if st.button("üìÅ B·∫Øt ƒë·∫ßu x·ª≠ l√Ω th∆∞ m·ª•c"):
        if folder_path and os.path.isdir(folder_path):
            image_files = [f for f in os.listdir(folder_path) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]
            
            if not image_files:
                st.error("Kh√¥ng t√¨m th·∫•y file ·∫£nh n√†o trong th∆∞ m·ª•c ƒë√£ ch·ªçn.")
            else:
                st.info(f"T√¨m th·∫•y **{len(image_files)}** ·∫£nh. B·∫Øt ƒë·∫ßu x·ª≠ l√Ω...")
                
                progress_bar = st.progress(0)
                all_results = []

                
                # N∆°i hi·ªÉn th·ªã ·∫£nh
                image_placeholder = st.empty()
                
                for i, image_name in enumerate(image_files):
                    image_path = os.path.join(folder_path, image_name)
                    frame = cv2.imread(image_path)
                    
                    st.subheader(f"ƒêang x·ª≠ l√Ω: {image_name}")
                    result_image, results_list = process_image(frame, image_name)
                    
                    # Hi·ªÉn th·ªã ·∫£nh k·∫øt qu·∫£
                    image_placeholder.image(result_image, channels="BGR", caption=f"K·∫øt qu·∫£ cho: {image_name}", use_column_width=True)
                    
                    if results_list:
                        all_results.extend(results_list)

                    # C·∫≠p nh·∫≠t progress bar
                    progress_bar.progress((i + 1) / len(image_files))
                    time.sleep(0.1) # T·∫°m d·ª´ng ƒë·ªÉ UI m∆∞·ª£t h∆°n
                
                st.success("üéâ Ho√†n t·∫•t x·ª≠ l√Ω to√†n b·ªô th∆∞ m·ª•c!")
                if all_results:
                    st.subheader("T·ªïng h·ª£p k·∫øt qu·∫£:")
                    df_all_results = pd.DataFrame(all_results)
                    st.dataframe(df_all_results)

                    @st.cache_data
                    def convert_df_to_csv(df):
                        return df.to_csv(index=False).encode('utf-8')
                    
                    csv_data = convert_df_to_csv(df_all_results)
                    st.download_button(
                        label="üì• T·∫£i t·∫•t c·∫£ k·∫øt qu·∫£ (CSV)",
                        data=csv_data,
                        file_name="results_full_folder.csv",
                        mime='text/csv',
                    )
                else:
                    st.info("Kh√¥ng nh·∫≠n di·ªán ƒë∆∞·ª£c bi·ªÉn s·ªë n√†o trong to√†n b·ªô th∆∞ m·ª•c.")

        else:
            st.error("ƒê∆∞·ªùng d·∫´n th∆∞ m·ª•c kh√¥ng h·ª£p l·ªá. Vui l√≤ng ki·ªÉm tra l·∫°i.")

elif app_mode == "ALPR t·ª´ Video":
    st.header("Ch·∫ø ƒë·ªô 3: X·ª≠ l√Ω t·ª´ m·ªôt file Video")
    
    frame_skip = st.sidebar.slider("X·ª≠ l√Ω m·ªói N khung h√¨nh (frame skip)", min_value=1, max_value=30, value=10,
                                        help="Gi√° tr·ªã c√†ng cao, x·ª≠ l√Ω c√†ng nhanh nh∆∞ng c√≥ th·ªÉ b·ªè l·ª° bi·ªÉn s·ªë. Gi√° tr·ªã 1 l√† x·ª≠ l√Ω m·ªçi khung h√¨nh.")

    uploaded_video = st.file_uploader("T·∫£i l√™n m·ªôt video (MP4, MOV, AVI)...", type=["mp4", "mov", "avi"])

    if uploaded_video is not None:
        if st.button("üé¨ B·∫Øt ƒë·∫ßu x·ª≠ l√Ω Video"):
            # T·∫°o file t·∫°m ƒë·ªÉ OpenCV c√≥ th·ªÉ ƒë·ªçc
            tfile = tempfile.NamedTemporaryFile(delete=False)
            tfile.write(uploaded_video.read())

            cap = cv2.VideoCapture(tfile.name)
            total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
            fps = cap.get(cv2.CAP_PROP_FPS)
            width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
            height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))

            # Thi·∫øt l·∫≠p VideoWriter ƒë·ªÉ l∆∞u video k·∫øt qu·∫£
            output_video_path = tempfile.NamedTemporaryFile(delete=False, suffix='.mp4').name
            fourcc = cv2.VideoWriter_fourcc(*'mp4v')
            out_writer = cv2.VideoWriter(output_video_path, fourcc, fps, (width, height))

            # C√°c bi·∫øn ƒë·ªÉ theo d√µi ti·∫øn tr√¨nh
            progress_bar = st.progress(0)
            status_text = st.empty()
            image_placeholder = st.empty()
            # all_results = []
            # seen_plates = set() # D√πng ƒë·ªÉ tr√°nh l∆∞u tr√πng l·∫∑p bi·ªÉn s·ªë
            best_results = {}
            frame_count = 0
            with st.spinner(f"ƒêang x·ª≠ l√Ω video... c√≥ t·ªïng c·ªông {total_frames} khung h√¨nh."):
                while cap.isOpened():
                    ret, frame = cap.read()
                    if not ret:
                        break
                    
                    frame_count += 1
                    
                    # Ch·ªâ x·ª≠ l√Ω khung h√¨nh n·∫øu n√≥ l√† frame ƒë·∫ßu ti√™n ho·∫∑c ƒë·∫øn l∆∞·ª£t skip
                    if frame_count % frame_skip == 0 or frame_count == 1:
                        status_text.text(f"ƒêang x·ª≠ l√Ω khung h√¨nh {frame_count}/{total_frames}...")
                        result_image, results_list = process_image(frame, f"frame_{frame_count}")
                        
                        if results_list:
                            for result in results_list:
                                lp_text = result['full_text']
                                # Chuy·ªÉn ƒë·ªïi confidence sang ki·ªÉu float ƒë·ªÉ so s√°nh
                                new_confidence = float(result['avg_confidence'])

                                # N·∫øu bi·ªÉn s·ªë ch∆∞a c√≥ trong k·∫øt qu·∫£ ho·∫∑c c√≥ confidence cao h∆°n,
                                # th√¨ l∆∞u ho·∫∑c c·∫≠p nh·∫≠t k·∫øt qu·∫£ m·ªõi.
                                if lp_text not in best_results or new_confidence > float(best_results[lp_text]['avg_confidence']):
                                    best_results[lp_text] = result
                        
                        image_placeholder.image(result_image, channels="BGR", caption=f"Khung h√¨nh {frame_count}")
                        out_writer.write(result_image)
                    else:
                        # V·ªõi c√°c frame b·ªã b·ªè qua, v·∫´n ghi v√†o video output ƒë·ªÉ kh√¥ng b·ªã gi·∫≠t
                        out_writer.write(frame)

                    # C·∫≠p nh·∫≠t progress bar
                    progress_bar.progress(frame_count / total_frames)

            # Gi·∫£i ph√≥ng t√†i nguy√™n
            cap.release()
            out_writer.release()

            st.success("üéâ Ho√†n t·∫•t x·ª≠ l√Ω video!")
            
            # Hi·ªÉn th·ªã video k·∫øt qu·∫£
            st.video(output_video_path)

            if best_results:
                st.subheader("T·ªïng h·ª£p c√°c bi·ªÉn s·ªë ƒë√£ nh·∫≠n di·ªán (k·∫øt qu·∫£ t·ªët nh·∫•t cho m·ªói xe):")
                # Chuy·ªÉn c√°c gi√° tr·ªã c·ªßa dictionary th√†nh list ƒë·ªÉ t·∫°o DataFrame
                final_results = list(best_results.values())
                df_all_results = pd.DataFrame(final_results)
                st.dataframe(df_all_results)

                @st.cache_data
                def convert_df_to_csv(df):
                    return df.to_csv(index=False).encode('utf-8')
                
                csv_data = convert_df_to_csv(df_all_results)
                st.download_button(
                    label="üì• T·∫£i t·∫•t c·∫£ k·∫øt qu·∫£ (CSV)",
                    data=csv_data,
                    file_name="video_results.csv",
                    mime='text/csv',
                )
            else:
                st.info("Kh√¥ng nh·∫≠n di·ªán ƒë∆∞·ª£c bi·ªÉn s·ªë n√†o trong video.")
# --- M√†n h√¨nh ch·ªù ---
else:
    st.info("Vui l√≤ng ch·ªçn m·ªôt ch·∫ø ƒë·ªô x·ª≠ l√Ω t·ª´ thanh c√¥ng c·ª• b√™n tr√°i.")
    st.image("https://www.luxoft.com/upload/medialibrary/729/automated_license_plate_recognition.png")