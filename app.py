# app.py

import streamlit as st
import cv2
import pandas as pd
import numpy as np
import tensorflow as tf
import os
import time
from pathlib import Path
import tempfile # Th∆∞ vi·ªán ƒë·ªÉ x·ª≠ l√Ω file t·∫°m
import io
import zipfile

# Import c√°c module t·ª´ th∆∞ m·ª•c src
from src import config
from src.vehicle_detector import VehicleDetector
from src.lp_detector import LicensePlateDetector
from src import preprocessor
from src.ocr_reader import OcrReader

# --- C·∫•u h√¨nh trang Streamlit ---
st.set_page_config(
    page_title="H·ªá th·ªëng Nh·∫≠n d·∫°ng Bi·ªÉn s·ªë xe",
    page_icon="üöó",
    layout="wide",
    initial_sidebar_state="expanded",
)

st.title("üöó Giao di·ªán Nh·∫≠n d·∫°ng Bi·ªÉn s·ªë xe (ALPR)")

# --- T·∫£i v√† Cache Model ---
@st.cache_resource
def load_models():
    """T·∫£i t·∫•t c·∫£ c√°c model v√† cache ch√∫ng."""
    with st.spinner('ƒêang t·∫£i c√°c model AI, vui l√≤ng ch·ªù...'):
        vehicle_detector = VehicleDetector(config.VEHICLE_DETECTION_MODEL_PATH)
        lp_detector = LicensePlateDetector(config.LP_DETECTION_MODEL_PATH)
        denoising_model = tf.keras.models.load_model(config.DENOISING_MODEL_PATH, compile=False)
        ocr = OcrReader(config.PADDLEOCR_MODEL_DIR, config.CHAR_DICT_PATH)

    if not all([vehicle_detector.model, lp_detector.model, denoising_model, ocr.ocr_reader]):
        st.error("L·ªói nghi√™m tr·ªçng: M·ªôt ho·∫∑c nhi·ªÅu model kh√¥ng th·ªÉ t·∫£i. Vui l√≤ng ki·ªÉm tra ƒë∆∞·ªùng d·∫´n trong file config.py.")
        return None
    return vehicle_detector, lp_detector, denoising_model, ocr

# T·∫£i model
models = load_models()
if models:
    vehicle_detector, lp_detector, denoising_model, ocr = models
    st.sidebar.success("T·∫£i model th√†nh c√¥ng!")
else:
    st.stop()


def process_single_vehicle(vehicle_crop, vehicle_id, lp_conf, two_line_ratio, verbose=False):
    processed_vehicle_img = vehicle_crop.copy()
    results_list = []

    lp_box = lp_detector.detect(vehicle_crop, lp_conf)
    if lp_box is None:
        return processed_vehicle_img, []

    lp_x1, lp_y1, lp_x2, lp_y2 = lp_box
    lp_crop = vehicle_crop[int(lp_y1):int(lp_y2), int(lp_x1):int(lp_x2)]

    images_for_ocr = preprocessor.process_lp_for_ocr(lp_crop, denoising_model, two_line_ratio=two_line_ratio)
    if not images_for_ocr:
        return processed_vehicle_img, []

    full_text, avg_confidence = ocr.recognize(images_for_ocr, vehicle_id, verbose=verbose)

    if full_text:
        results_list.append({
            'frame': vehicle_id.split('_')[0], 'id_vehicle': vehicle_id,
            'full_text': full_text, 'avg_confidence': f"{avg_confidence:.4f}"
        })

        label = f"LP:{full_text}"
        cv2.rectangle(processed_vehicle_img, (int(lp_x1), int(lp_y1)), (int(lp_x2), int(lp_y2)), (36, 255, 12), 2)
        (w, h), _ = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.7, 2)
        cv2.rectangle(processed_vehicle_img, (int(lp_x1), int(lp_y1) - h - 10), (int(lp_x1) + w, int(lp_y1)), (36, 255, 12), -1)
        cv2.putText(processed_vehicle_img, label, (int(lp_x1), int(lp_y1) - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 0), 2)

    return processed_vehicle_img, results_list


def run_alpr_on_frame(frame, image_name, vehicle_conf, lp_conf, two_line_ratio, verbose=False):
    output_image = frame.copy()
    all_results = []

    status_context = st.status(f"üîç ƒêang x·ª≠ l√Ω {image_name}...", expanded=True) if verbose else None

    vehicle_boxes = vehicle_detector.detect(frame, vehicle_conf)

    if not np.any(vehicle_boxes):
        if verbose and status_context:
            status_context.update(label="Kh√¥ng t√¨m th·∫•y xe.", state="warning", expanded=False)
        return output_image, []

    if verbose and status_context:
        status_context.update(label=f"T√¨m th·∫•y {len(vehicle_boxes)} xe. ƒêang nh·∫≠n d·∫°ng...", state="running")

    for i, (x1, y1, x2, y2) in enumerate(vehicle_boxes):
        vehicle_id = f"{Path(image_name).stem}_{i}"
        vehicle_crop = frame[int(y1):int(y2), int(x1):int(x2)]

        processed_vehicle, results = process_single_vehicle(
            vehicle_crop, vehicle_id, lp_conf, two_line_ratio, verbose=verbose
        )

        output_image[int(y1):int(y2), int(x1):int(x2)] = processed_vehicle

        if results:
            all_results.extend(results)
            cv2.rectangle(output_image, (int(x1), int(y1)), (int(x2), int(y2)), (36, 255, 12), 2)

    if verbose and status_context:
        status_context.update(label="Ho√†n t·∫•t!", state="complete", expanded=False)

    return output_image, all_results

# --- GIAO DI·ªÜN CH√çNH ---

st.sidebar.header("Ch·ªçn ch·∫ø ƒë·ªô")
app_mode = st.sidebar.selectbox("Vui l√≤ng ch·ªçn ch·∫ø ƒë·ªô x·ª≠ l√Ω:",
                                ["Ch·ªçn ch·∫ø ƒë·ªô...", "ALPR 1 ·∫£nh", "ALPR 1 th∆∞ m·ª•c",  "ALPR t·ª´ Video"])

st.sidebar.header("‚öôÔ∏è Tinh ch·ªânh tham s·ªë")
st.sidebar.info("C√°c tham s·ªë n√†y s·∫Ω ƒë∆∞·ª£c √°p d·ª•ng cho t·∫•t c·∫£ c√°c ch·∫ø ƒë·ªô.")
vehicle_conf_adj = st.sidebar.slider("Ng∆∞·ª°ng tin c·∫≠y ph√°t hi·ªán XE", 0.05, 0.95, config.VEHICLE_CONF_THRESHOLD, 0.05)
lp_conf_adj = st.sidebar.slider("Ng∆∞·ª°ng tin c·∫≠y ph√°t hi·ªán BI·ªÇN S·ªê", 0.05, 0.95, config.LP_CONF_THRESHOLD, 0.05)
ratio_adj = st.sidebar.slider("T·ª∑ l·ªá nh·∫≠n di·ªán bi·ªÉn 2 d√≤ng", 0.2, 1.0, config.TWO_LINE_LP_ASPECT_RATIO_THRESHOLD, 0.05,
                            help="Gi√° tr·ªã c√†ng th·∫•p, c√†ng d·ªÖ nh·∫≠n di·ªán bi·ªÉn s·ªë d·ªçc (2 d√≤ng).")

# --- CH·∫æ ƒê·ªò 1: X·ª¨ L√ù 1 ·∫¢NH ---
if app_mode == "ALPR 1 ·∫£nh":
    st.header("Ch·∫ø ƒë·ªô 1: X·ª≠ l√Ω m·ªôt ·∫£nh duy nh·∫•t")
    uploaded_file = st.file_uploader("T·∫£i l√™n m·ªôt ·∫£nh (JPG, PNG)...", type=["jpg", "jpeg", "png"])

    if uploaded_file is not None:
        file_bytes = np.asarray(bytearray(uploaded_file.read()), dtype=np.uint8)
        frame = cv2.imdecode(file_bytes, 1)

        col1, col2 = st.columns(2)
        with col1:
            st.image(frame, channels="BGR", caption="·∫¢nh g·ªëc")

        if st.button("üöÄ B·∫Øt ƒë·∫ßu x·ª≠ l√Ω"):
            result_image, results_list = run_alpr_on_frame(
                frame, uploaded_file.name, vehicle_conf_adj, lp_conf_adj, ratio_adj, verbose=True
            )

            with col2:
                st.image(result_image, channels="BGR", caption="·∫¢nh k·∫øt qu·∫£")

            if results_list:
                st.subheader("K·∫øt qu·∫£ nh·∫≠n di·ªán:")
                df_results = pd.DataFrame(results_list)
                st.dataframe(df_results)

                @st.cache_data
                def convert_df_to_csv(df):
                    return df.to_csv(index=False).encode('utf-8')

                csv_data = convert_df_to_csv(df_results)
                st.download_button(
                    label="üì• T·∫£i k·∫øt qu·∫£ (CSV)",
                    data=csv_data,
                    file_name=f"result_{Path(uploaded_file.name).stem}.csv",
                    mime='text/csv',
                )
            else:
                st.info("Kh√¥ng nh·∫≠n di·ªán ƒë∆∞·ª£c bi·ªÉn s·ªë n√†o trong ·∫£nh.")

# --- CH·∫æ ƒê·ªò 2: X·ª¨ L√ù TH∆Ø M·ª§C (ƒê√É C·∫¨P NH·∫¨T) ---
elif app_mode == "ALPR 1 th∆∞ m·ª•c":
    st.header("Ch·∫ø ƒë·ªô 2: X·ª≠ l√Ω nhi·ªÅu ·∫£nh t·ª´ m·ªôt th∆∞ m·ª•c")
    
    # Cho ph√©p ng∆∞·ªùi d√πng t·∫£i l√™n nhi·ªÅu file
    uploaded_files = st.file_uploader(
        "T·∫£i l√™n c√°c ·∫£nh (JPG, PNG) t·ª´ th∆∞ m·ª•c c·ªßa b·∫°n...", 
        type=["jpg", "jpeg", "png"],
        accept_multiple_files=True
    )

    if uploaded_files:
        st.info(f"ƒê√£ ch·ªçn **{len(uploaded_files)}** ·∫£nh. Nh·∫•n n√∫t b√™n d∆∞·ªõi ƒë·ªÉ b·∫Øt ƒë·∫ßu.")
        
        if st.button("üìÅ B·∫Øt ƒë·∫ßu x·ª≠ l√Ω c√°c ·∫£nh ƒë√£ ch·ªçn"):
            progress_bar = st.progress(0, text="B·∫Øt ƒë·∫ßu x·ª≠ l√Ω...")
            all_results = []
            
            # D√πng io.BytesIO ƒë·ªÉ t·∫°o file zip trong b·ªô nh·ªõ
            zip_buffer = io.BytesIO()
            
            # Dictionary ƒë·ªÉ l∆∞u ·∫£nh k·∫øt qu·∫£ trong b·ªô nh·ªõ
            processed_images_data = {}

            for i, uploaded_file in enumerate(uploaded_files):
                image_name = uploaded_file.name
                progress_text = f"ƒêang x·ª≠ l√Ω ·∫£nh: {image_name} ({i + 1}/{len(uploaded_files)})"
                progress_bar.progress((i + 1) / len(uploaded_files), text=progress_text)
                
                # ƒê·ªçc ·∫£nh t·ª´ file t·∫£i l√™n
                file_bytes = np.asarray(bytearray(uploaded_file.read()), dtype=np.uint8)
                frame = cv2.imdecode(file_bytes, 1)

                # Ch·∫°y ALPR tr√™n ·∫£nh
                result_image, results_list = run_alpr_on_frame(
                    frame, image_name, vehicle_conf_adj, lp_conf_adj, ratio_adj, verbose=False
                )
                
                # M√£ h√≥a ·∫£nh k·∫øt qu·∫£ sang ƒë·ªãnh d·∫°ng PNG ƒë·ªÉ l∆∞u v√†o b·ªô nh·ªõ
                is_success, buffer = cv2.imencode(".png", result_image)
                if is_success:
                    processed_images_data[image_name] = io.BytesIO(buffer)

                # Th√™m t√™n file v√†o k·∫øt qu·∫£ ƒë·ªÉ xu·∫•t CSV
                if results_list:
                    for result in results_list:
                        result['image_name'] = image_name
                    all_results.extend(results_list)
                
                time.sleep(0.1) # D·ª´ng m·ªôt ch√∫t ƒë·ªÉ UI m∆∞·ª£t h∆°n

            progress_bar.empty()
            st.success("üéâ Ho√†n t·∫•t x·ª≠ l√Ω t·∫•t c·∫£ ·∫£nh!")

            # --- T·∫†O C√ÅC N√öT DOWNLOAD ---
            col1, col2 = st.columns(2)

            # 1. N√öT T·∫¢I FILE ZIP
            with col1:
                if processed_images_data:
                    with zipfile.ZipFile(zip_buffer, "w", zipfile.ZIP_DEFLATED) as zf:
                        for filename, data in processed_images_data.items():
                            zf.writestr(f"processed_{filename}", data.getvalue())
                    
                    st.download_button(
                        label="üì• T·∫£i t·∫•t c·∫£ ·∫£nh k·∫øt qu·∫£ (.zip)",
                        data=zip_buffer.getvalue(),
                        file_name="processed_images.zip",
                        mime="application/zip",
                        use_container_width=True
                    )

            # 2. N√öT T·∫¢I FILE CSV
            with col2:
                if all_results:
                    df = pd.DataFrame(all_results)
                    # ƒê·ªïi t√™n v√† s·∫Øp x·∫øp l·∫°i c√°c c·ªôt theo y√™u c·∫ßu
                    df.rename(columns={
                        'id_vehicle': 'vehicle_id',
                        'full_text': 'text',
                        'avg_confidence': 'confidence'
                    }, inplace=True)
                    df_final = df[['image_name', 'vehicle_id', 'text', 'confidence']]

                    csv_data = df_final.to_csv(index=False).encode('utf-8')
                    st.download_button(
                        label="üì• T·∫£i t·∫•t c·∫£ k·∫øt qu·∫£ (.csv)",
                        data=csv_data,
                        file_name="folder_alpr_results.csv",
                        mime="text/csv",
                        use_container_width=True
                    )
            
            # Hi·ªÉn th·ªã b·∫£ng k·∫øt qu·∫£ t·ªïng h·ª£p
            if all_results:
                st.subheader("T·ªïng h·ª£p k·∫øt qu·∫£:")
                st.dataframe(df_final)
            else:
                st.info("Kh√¥ng nh·∫≠n di·ªán ƒë∆∞·ª£c bi·ªÉn s·ªë n√†o trong c√°c ·∫£nh ƒë√£ ch·ªçn.")


# --- CH·∫æ ƒê·ªò 3: X·ª¨ L√ù VIDEO ---
# --- CH·∫æ ƒê·ªò 3: X·ª¨ L√ù VIDEO (ƒê√É C·∫¨P NH·∫¨T V·ªöI B·ªò THEO D√ïI XE) ---
# --- CH·∫æ ƒê·ªò 3: X·ª¨ L√ù VIDEO (PHI√äN B·∫¢N T·ªêI ∆ØU H√ìA) ---
elif app_mode == "ALPR t·ª´ Video":
    st.header("Ch·∫ø ƒë·ªô 3: X·ª≠ l√Ω t·ª´ m·ªôt file Video")
    st.sidebar.subheader("Tinh ch·ªânh Video")
    # TƒÉng gi√° tr·ªã m·∫∑c ƒë·ªãnh c·ªßa frame_skip v√¨ tracker ƒë√£ hi·ªáu qu·∫£ h∆°n
    frame_skip = st.sidebar.slider("X·ª≠ l√Ω m·ªói N khung h√¨nh (frame skip)", 1, 30, 5)
    # Th√™m t√πy ch·ªçn cho kho·∫£ng th·ªùi gian ph√°t hi·ªán l·∫°i xe
    detection_interval = st.sidebar.slider("Ph√°t hi·ªán l·∫°i xe sau m·ªói X khung h√¨nh x·ª≠ l√Ω", 1, 50, 10, help="Gi√° tr·ªã c√†ng cao, t·ªëc ƒë·ªô c√†ng nhanh nh∆∞ng c√≥ th·ªÉ b·ªè l·ª° xe m·ªõi. Gi√° tr·ªã n√†y ƒë∆∞·ª£c nh√¢n v·ªõi Frame Skip.")

    uploaded_video = st.file_uploader("T·∫£i l√™n m·ªôt video (MP4, MOV, AVI)...", type=["mp4", "mov", "avi"])

    roi_rect = None
    if uploaded_video is not None:
        tfile = tempfile.NamedTemporaryFile(delete=False)
        tfile.write(uploaded_video.read())
        tfile.close()

        video_filename = uploaded_video.name
        cap_preview = cv2.VideoCapture(tfile.name)
        ret, first_frame = cap_preview.read()
        cap_preview.release()

        if ret:
            st.subheader("B∆∞·ªõc 1: (B·∫Øt bu·ªôc) X√°c ƒë·ªãnh V√πng Quan T√¢m (Region of Interest)")
            st.info("B·ªô ƒë·∫øm v√† nh·∫≠n d·∫°ng s·∫Ω ch·ªâ ho·∫°t ƒë·ªông v·ªõi nh·ªØng xe ƒëi v√†o v√πng ROI b·∫°n ƒë√£ v·∫Ω.")
            
            preview_frame = first_frame.copy()
            height, width, _ = preview_frame.shape

            col1, col2 = st.columns(2)
            with col1:
                x_min = st.slider("ROI X-min", 0, width, 0, 1)
                x_max = st.slider("ROI X-max", 0, width, width, 1)
            with col2:
                y_min = st.slider("ROI Y-min", 0, height, 0, 1)
                y_max = st.slider("ROI Y-max", 0, height, height, 1)

            if x_min >= x_max: x_max = x_min + 1
            if y_min >= y_max: y_max = y_min + 1

            roi_rect = (x_min, y_min, x_max, y_max)
            cv2.rectangle(preview_frame, (x_min, y_min), (x_max, y_max), (36, 255, 12), 3)
            st.image(preview_frame, channels="BGR", caption="Khung h√¨nh ƒë·∫ßu ti√™n v·ªõi ROI")

        st.subheader("B∆∞·ªõc 2: B·∫Øt ƒë·∫ßu x·ª≠ l√Ω video")
        if st.button("üé¨ B·∫Øt ƒë·∫ßu x·ª≠ l√Ω Video"):
            if roi_rect is None or (roi_rect[0] == 0 and roi_rect[2] == width and roi_rect[1] == 0 and roi_rect[3] == height):
                st.warning("Vui l√≤ng x√°c ƒë·ªãnh m·ªôt v√πng ROI c·ª• th·ªÉ ·ªü B∆∞·ªõc 1 ƒë·ªÉ b·ªô ƒë·∫øm ho·∫°t ƒë·ªông ch√≠nh x√°c.")
                st.stop()

            cap = cv2.VideoCapture(tfile.name)
            total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
            fps = cap.get(cv2.CAP_PROP_FPS)
            out_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
            out_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
            output_video_path = tempfile.NamedTemporaryFile(delete=False, suffix='.mp4').name
            fourcc = cv2.VideoWriter_fourcc(*'mp4v')
            out_writer = cv2.VideoWriter(output_video_path, fourcc, fps, (out_width, out_height))

            # --- KH·ªûI T·∫†O C√ÅC BI·∫æN CHO TRACKER T·ªêI ∆ØU ---
            trackers = {} # {tracker_id: {'tracker': cv2.Tracker, 'box': (x,y,w,h), 'id_vehicle': None}}
            next_tracker_id = 0
            vehicle_pass_count = 0

            progress_bar = st.progress(0, text="B·∫Øt ƒë·∫ßu x·ª≠ l√Ω...")
            status_text = st.empty()
            image_placeholder = st.empty()
            all_video_results = []
            frame_count = 0
            processed_frame_count = 0

            with st.spinner("ƒêang x·ª≠ l√Ω video v·ªõi b·ªô theo d√µi t·ªëi ∆∞u..."):
                while cap.isOpened():
                    ret, frame = cap.read()
                    if not ret: break
                    frame_count += 1
                    
                    # Lu√¥n b·∫Øt ƒë·∫ßu v·ªõi m·ªôt khung h√¨nh s·∫°ch ƒë·ªÉ v·∫Ω l√™n
                    display_frame = frame.copy()
                    
                    # KI·ªÇM TRA XEM ƒê√ÇY C√ì PH·∫¢I L√Ä KHUNG H√åNH C·∫¶N X·ª¨ L√ù KH√îNG
                    if frame_count % frame_skip == 0:
                        processed_frame_count += 1
                        status_text.text(f"ƒêang x·ª≠ l√Ω khung h√¨nh {frame_count}/{total_frames}...")

                        # 1. CH·∫†Y PH√ÅT HI·ªÜN XE ƒê·ªäNH K·ª≤
                        if processed_frame_count % detection_interval == 0:
                            vehicle_boxes = vehicle_detector.detect(frame, vehicle_conf_adj)
                            for (x1, y1, x2, y2) in vehicle_boxes:
                                box_w, box_h = (x2 - x1), (y2 - y1)
                                center_x, center_y = x1 + box_w / 2, y1 + box_h / 2
                                
                                is_new = True
                                for tid, tdata in trackers.items():
                                    tx, ty, tw, th = tdata['box']
                                    if abs(center_x - (tx + tw/2)) < tw/2 and abs(center_y - (ty + th/2)) < th/2:
                                        is_new = False
                                        break
                                
                                if is_new:
                                    bbox_int = (int(x1), int(y1), int(box_w), int(box_h))
                                    new_tracker = cv2.TrackerCSRT_create()
                                    new_tracker.init(frame, bbox_int)
                                    trackers[next_tracker_id] = {
                                        'tracker': new_tracker,
                                        'box': bbox_int,
                                        'id_vehicle': None,
                                        'processed_image': None
                                    }
                                    next_tracker_id += 1

                        # 2. C·∫¨P NH·∫¨T V·ªä TR√ç T·ª™ C√ÅC TRACKER
                        failed_trackers = []
                        for tracker_id, tdata in trackers.items():
                            success, box = tdata['tracker'].update(frame)
                            if success:
                                trackers[tracker_id]['box'] = box
                                x, y, w, h = [int(v) for v in box]
                                center_x, center_y = x + w / 2, y + h / 2
                                rx1, ry1, rx2, ry2 = roi_rect

                                if rx1 < center_x < rx2 and ry1 < center_y < ry2:
                                    if tdata['id_vehicle'] is None:
                                        vehicle_pass_count += 1
                                        assigned_id = vehicle_pass_count
                                        trackers[tracker_id]['id_vehicle'] = assigned_id

                                        vehicle_crop = frame[y:y+h, x:x+w]
                                        processed_vehicle, results = process_single_vehicle(
                                            vehicle_crop, f"v_{assigned_id}", lp_conf_adj, ratio_adj, verbose=False
                                        )
                                        trackers[tracker_id]['processed_image'] = processed_vehicle

                                        if results:
                                            for r in results:
                                                r['frame'] = frame_count
                                                r['id_vehicle'] = assigned_id
                                            all_video_results.extend(results)
                            else:
                                failed_trackers.append(tracker_id)
                        
                        # 3. X√ìA C√ÅC TRACKER B·ªä L·ªñI
                        for tracker_id in failed_trackers:
                            del trackers[tracker_id]

                    # ---- LOGIC V·∫º (CH·∫†Y TR√äN M·ªåI KHUNG H√åNH) ----
                    # V·∫Ω v√πng ROI
                    rx1, ry1, rx2, ry2 = roi_rect
                    cv2.rectangle(display_frame, (rx1, ry1), (rx2, ry2), (36, 255, 12), 2)
                    
                    # V·∫Ω t·∫•t c·∫£ c√°c xe ƒëang ƒë∆∞·ª£c theo d√µi
                    for tracker_id, tdata in trackers.items():
                        x, y, w, h = [int(v) for v in tdata['box']]
                        
                        # V·∫Ω l·∫°i ·∫£nh xe ƒë√£ x·ª≠ l√Ω n·∫øu c√≥
                        # V·∫Ω l·∫°i ·∫£nh xe ƒë√£ x·ª≠ l√Ω n·∫øu c√≥
                        if tdata.get('processed_image') is not None:
                            img_h, img_w, _ = display_frame.shape
                            crop_h, crop_w, _ = tdata['processed_image'].shape
                            
                            # ---- S·ª¨A L·ªñI: TH√äM KI·ªÇM TRA TO√ÄN DI·ªÜN H∆†N ----
                            # ƒê·∫£m b·∫£o to√†n b·ªô v√πng ·∫£nh n·∫±m tr·ªçn trong khung h√¨nh tr∆∞·ªõc khi v·∫Ω
                            if y >= 0 and x >= 0 and (y + crop_h) <= img_h and (x + crop_w) <= img_w:
                                display_frame[y:y+crop_h, x:x+crop_w] = tdata['processed_image']
                        
                        # V·∫Ω h·ªôp v√† ID
                        assigned_id = tdata.get('id_vehicle')
                        if assigned_id is not None:
                            id_label = f"ID: {assigned_id}"
                            cv2.rectangle(display_frame, (x, y), (x + w, y + h), (36, 255, 12), 2)
                            (lw, lh), _ = cv2.getTextSize(id_label, cv2.FONT_HERSHEY_SIMPLEX, 0.7, 2)
                            cv2.rectangle(display_frame, (x, y - lh - 10), (x + lw, y), (36, 255, 12), -1)
                            cv2.putText(display_frame, id_label, (x, y - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 0), 2)
                    
                    # ---- GHI KHUNG H√åNH V√Ä C·∫¨P NH·∫¨T GIAO DI·ªÜN ----
                    # Ghi l·∫°i M·ªåI khung h√¨nh ƒë√£ ƒë∆∞·ª£c v·∫Ω v√†o video output
                    out_writer.write(display_frame)
                    
                    # Ch·ªâ c·∫≠p nh·∫≠t giao di·ªán tr√™n c√°c frame ƒë√£ x·ª≠ l√Ω ƒë·ªÉ tr√°nh lag
                    if frame_count % frame_skip == 0:
                        image_placeholder.image(display_frame, channels="BGR")
                        progress_bar.progress(frame_count / total_frames)
            cap.release()
            out_writer.release()
            os.remove(tfile.name) 
            st.success("üéâ Ho√†n t·∫•t x·ª≠ l√Ω video!")

            # --- HI·ªÇN TH·ªä V√Ä T·∫¢I K·∫æT QU·∫¢ VIDEO ---
            st.subheader("K·∫øt qu·∫£ Video ƒë√£ x·ª≠ l√Ω")
            with open(output_video_path, 'rb') as f:
                video_bytes = f.read()
            st.video(video_bytes)
            st.download_button(label="üì• T·∫£i video ƒë√£ x·ª≠ l√Ω", data=video_bytes, file_name=f"processed_{video_filename}", mime="video/mp4")
            os.remove(output_video_path)

            if all_video_results:
                st.subheader("T·ªïng h·ª£p c√°c l∆∞·ª£t nh·∫≠n di·ªán trong video:")
                df_all = pd.DataFrame(all_video_results)
                df_all.rename(columns={'full_text': 'text', 'avg_confidence': 'confidence'}, inplace=True)
                df_all['confidence'] = pd.to_numeric(df_all['confidence']) # ƒê·∫£m b·∫£o confidence l√† s·ªë
                
                # Gi·ªØ l·∫°i k·∫øt qu·∫£ t·ªët nh·∫•t cho m·ªói ID xe
                df_final = df_all.loc[df_all.groupby('id_vehicle')['confidence'].idxmax()]
                df_final = df_final[['frame', 'id_vehicle', 'text', 'confidence']].sort_values(by='id_vehicle')
                df_final['confidence'] = df_final['confidence'].apply(lambda x: f"{x:.4f}")

                st.dataframe(df_final)

                csv_data = df_final.to_csv(index=False).encode('utf-8')
                st.download_button(label="üì• T·∫£i k·∫øt qu·∫£ nh·∫≠n di·ªán (CSV)", data=csv_data, file_name=f"results_{Path(video_filename).stem}.csv", mime='text/csv')
            else:
                st.info("Kh√¥ng nh·∫≠n di·ªán ƒë∆∞·ª£c bi·ªÉn s·ªë n√†o h·ª£p l·ªá trong video.")

# --- M√†n h√¨nh ch·ªù ---
else:
    st.info("Vui l√≤ng ch·ªçn m·ªôt ch·∫ø ƒë·ªô x·ª≠ l√Ω t·ª´ thanh c√¥ng c·ª• b√™n tr√°i.")
    st.image("https://www.luxoft.com/upload/medialibrary/729/automated_license_plate_recognition.png")